link <- "https://www.zillow.com/brooklyn-new-york-ny/rentals/?searchQueryState=%7B%22mapBounds%22%3A%7B%22north%22%3A40.793235860408586%2C%22east%22%3A-73.90149779524465%2C%22south%22%3A40.642050580241396%2C%22west%22%3A-74.101654960772%7D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22fsba%22%3A%7B%22value%22%3Afalse%7D%2C%22fsbo%22%3A%7B%22value%22%3Afalse%7D%2C%22nc%22%3A%7B%22value%22%3Afalse%7D%2C%22fore%22%3A%7B%22value%22%3Afalse%7D%2C%22cmsn%22%3A%7B%22value%22%3Afalse%7D%2C%22auc%22%3A%7B%22value%22%3Afalse%7D%2C%22fr%22%3A%7B%22value%22%3Atrue%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%2C%22mp%22%3A%7B%22max%22%3A2000%7D%2C%22price%22%3A%7B%22max%22%3A381295%7D%2C%22sort%22%3A%7B%22value%22%3A%22paymenta%22%7D%7D%2C%22isListVisible%22%3Atrue%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A37607%2C%22regionType%22%3A17%7D%2C%7B%22regionId%22%3A12530%2C%22regionType%22%3A17%7D%5D%2C%22pagination%22%3A%7B%7D%2C%22mapZoom%22%3A12%7D"
page <- read_html(link)
page
library(pacman)
pacman::p_load(pacman, dplyr,rvest)
link <- "https://www.zillow.com/brooklyn-new-york-ny/rentals/?searchQueryState=%7B%22mapBounds%22%3A%7B%22north%22%3A40.793235860408586%2C%22east%22%3A-73.90149779524465%2C%22south%22%3A40.642050580241396%2C%22west%22%3A-74.101654960772%7D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22fsba%22%3A%7B%22value%22%3Afalse%7D%2C%22fsbo%22%3A%7B%22value%22%3Afalse%7D%2C%22nc%22%3A%7B%22value%22%3Afalse%7D%2C%22fore%22%3A%7B%22value%22%3Afalse%7D%2C%22cmsn%22%3A%7B%22value%22%3Afalse%7D%2C%22auc%22%3A%7B%22value%22%3Afalse%7D%2C%22fr%22%3A%7B%22value%22%3Atrue%7D%2C%22ah%22%3A%7B%22value%22%3Atrue%7D%2C%22mp%22%3A%7B%22max%22%3A2000%7D%2C%22price%22%3A%7B%22max%22%3A381295%7D%2C%22sort%22%3A%7B%22value%22%3A%22paymenta%22%7D%7D%2C%22isListVisible%22%3Atrue%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A37607%2C%22regionType%22%3A17%7D%2C%7B%22regionId%22%3A12530%2C%22regionType%22%3A17%7D%5D%2C%22pagination%22%3A%7B%7D%2C%22mapZoom%22%3A12%7D"
page <- read_html(link)
page
airline <- page %>% html_element(".iMKTKr")
airline
airline
airline <- page %>% html_node(".iMKTKr")
airline
airline <- page %>% html_node(".iMKTKr")%>% html_text()
airline
knitr::opts_chunk$set(echo = TRUE)
library(rjson)
library(pacman)
p_load(pacman,rjson,ggplot2,zoo,tm,SnowballC,textcat,caTools,rpart,rpart.plot,randomForest,caret,e1071,wordcloud )
Sys.setlocale("LC_ALL", "C")
data <- read.csv(../tripadvisor_hotel_reviews.csv)
head(data)
data <- read.csv(tripadvisor_hotel_reviews.csv)
data <- read.csv("tripadvisor_hotel_reviews.csv")
head(data)
data <- read.csv("tripadvisor_hotel_reviews.csv")
head(data)
ggplot(data = data, aes(x=Rating))
ggplot(data = data, aes(x=Rating))+geom_histogram()
data$Positive <- as.factor(data$Rating>3)
table(data$Positive)
table(data$Rating)
p_load(pacman,ggplot2,zoo,tm,SnowballC,textcat,caTools,rpart,rpart.plot,randomForest,caret,e1071,wordcloud,psych )
describe(data)
describe(data=data)
describe(data)
desc <- describe(data)
desc
print(desc)
describe(data)
corpus = VCorpus(VectorSource(data$Review))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords,stopwords("english"))
corpus = tm_map(corpus, stemDocument)
colnames(reviewsSparse) = make.names(colnames(reviewsSparse))
frequencies = DocumentTermMatrix(corpus)
sparse = removeSparseTerms(frequencies, 0.99)
reviewsSparse = as.data.frame(as.matrix(sparse))
colnames(reviewsSparse) = make.names(colnames(reviewsSparse))
reviewsSparse$positive = restaurant_reviews$positive
reviewsSparse$positive = data$Positive
View(reviewsSparse)
set.seed(174)
split = sample.split(reviewsSparse$positive, SplitRatio = 0.7)
reviewsSparse$split = split
train = subset(reviewsSparse, split==TRUE)
test = subset(reviewsSparse, split==FALSE)
table(train$positive)
prp(cartModel)
cartModel = rpart(positive ~ ., data=train, method="class")
prp(cartModel)
predictCART = predict(cartModel, newdata=test, type="class")
table(test$positive, predictCART)
(276+4429)/nrow(test)
knitr::opts_chunk$set(echo = TRUE)
predictCART = predict(cartModel, newdata=test, type="class")
table(test$positive, predictCART)
(276+4429)/nrow(test)
predictCART = predict(cartModel, newdata=test, type="class")
confMat <- table(test$positive, predictCART) #making confusion matrix
accuracy <- sum(diag(confMat))/sum(confMat) #measuring accuracy
accuracy
confMat
confMat
accuracy
cartModel = rpart(positive ~ ., data=train, method="class")
prp(cartModel)
cartModel = rpart(positive ~ ., data=train, method="class")
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("tripadvisor_hotel_reviews.csv")
head(data)
library(pacman)
p_load(pacman,ggplot2,zoo,tm,SnowballC,textcat,caTools,rpart,rpart.plot,randomForest,caret,e1071,wordcloud,psych )
Sys.setlocale("LC_ALL", "C")
describe(data)
table(data$Rating)
ggplot(data = data, aes(x=Rating))+geom_histogram()
data$Positive <- as.factor(data$Rating > 3)
table(data$Positive)
corpus = VCorpus(VectorSource(data$Review))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords,stopwords("english"))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
sparse = removeSparseTerms(frequencies, 0.99)
reviewsSparse = as.data.frame(as.matrix(sparse))
colnames(reviewsSparse) = make.names(colnames(reviewsSparse))
reviewsSparse$positive = data$Positive
set.seed(42)
split = sample.split(reviewsSparse$positive, SplitRatio = 0.7)
reviewsSparse$split = split
train = subset(reviewsSparse, split==TRUE)
test = subset(reviewsSparse, split==FALSE)
cartModel = rpart(positive ~ ., data=train, method="class")
prp(cartModel)
predictCART = predict(cartModel, newdata=test, type="class")
confMat <- table(test$positive, predictCART) #making confusion matrix
accuracy <- sum(diag(confMat))/sum(confMat) #measuring accuracy
confMat
accuracy
train(positive ~ ., data = train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid)
numFolds=trainControl(method = "cv", number = 10)
cpGrid = expand.grid(.cp=seq(0.001, 0.01, 0.001))
train(positive ~ ., data = train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid)
cartModelImproved = rpart(positive ~ ., data=train, method="class", cp= 0.002)
prp(cartModelImproved)
predictCARTImproved = predict(cartModelImproved, newdata=test, type="class")
confMatImprov <- table(test$positive, predictCARTImproved)
accuracyImprov <- sum(diag(confMatImprov))/sum(confMatImprov)
confMatImprov
accuracyImprov
preprocessString <- function(input_string) {
# Create a temporary corpus with the input string
corpus <- Corpus(VectorSource(input_string))
# Preprocessing steps
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
frequencies <- DocumentTermMatrix(corpus)
sparse <- removeSparseTerms(frequencies, 0.99)
reviewsSparse <- as.data.frame(as.matrix(sparse))
colnames(reviewsSparse) <- make.names(colnames(reviewsSparse))
# Return the preprocessed data frame
return(dtm_df)
}
reviewString <- "This hotel is so bad. it's dirty and the staff is very very rude! wouldn't recommend!"
reviewDf <- preprocessString(reviewString)
preprocessString <- function(input_string) {
# Create a temporary corpus with the input string
corpus <- Corpus(VectorSource(input_string))
# Preprocessing steps
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
frequencies <- DocumentTermMatrix(corpus)
sparse <- removeSparseTerms(frequencies, 0.99)
reviewsSparse <- as.data.frame(as.matrix(sparse))
colnames(reviewsSparse) <- make.names(colnames(reviewsSparse))
# Return the preprocessed data frame
return(reviewsSparse)
}
reviewString <- "This hotel is so bad. it's dirty and the staff is very very rude! wouldn't recommend!"
reviewDf <- preprocessString(reviewString)
print(reviewDf)
preprocessString <- function(input_string) {
# Create a temporary corpus with the input string
corpus <- VCorpus(VectorSource(input_string))
# Preprocessing steps
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
frequencies <- DocumentTermMatrix(corpus)
sparse <- removeSparseTerms(frequencies, 0.99)
reviewsSparse <- as.data.frame(as.matrix(sparse))
colnames(reviewsSparse) <- make.names(colnames(reviewsSparse))
# Return the preprocessed data frame
return(reviewsSparse)
}
reviewString <- "This hotel is so bad. it's dirty and the staff is very very rude! wouldn't recommend!"
reviewDf <- preprocessString(reviewString)
print(reviewDf)
print(predict(cartModelImproved,reviewDf,type = "class"))
print(predict(cartModelImproved,reviewDf,type = "class"))
print(predict(cartModelImproved,newdata= reviewDf,type = "class"))
View(reviewsSparse)
View(reviewDf)
View(reviewsSparse)
View(sparse)
preprocessString <- function(input_string) {
# Create a temporary corpus with the input string
corpus <- VCorpus(VectorSource(input_string))
# Preprocessing steps
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
frequencies <- DocumentTermMatrix(corpus)
sparse <- removeSparseTerms(frequencies, 0.99)
reviewsSparse <- as.data.frame(as.matrix(sparse))
colnames(reviewsSparse) <- make.names(colnames(reviewsSparse))
# Return the preprocessed data frame
return(reviewsSparse)
}
reviewString <- "This hotel is so bad. it's dirty and the staff is very very rude! wouldn't recommend!"
test <- preprocessString(reviewString)
print(reviewDf)
print(predict(cartModelImproved,newdata= reviewDf,type = "class"))
print(predict(cartModelImproved,newdata= test,type = "class"))
print(predict(cartModelImproved, test,type = "class"))
wordcloud(corpus, min.freq=400)
# Load the AFINN lexicon
data("afinn")
# Convert the corpus to a tidy format
tidy_corpus <- tidy(corpus)
p_load(pacman,ggplot2,zoo,tm,SnowballC,textcat,caTools,rpart,rpart.plot,randomForest,caret,e1071,wordcloud,psych,tidytext )
# Load the AFINN lexicon
data("afinn")
# Convert the corpus to a tidy format
tidy_corpus <- tidy(corpus)
# Perform sentiment analysis
sentiment_analysis <- tidy_corpus %>%
inner_join(afinn, by = c("term" = "word")) %>%
group_by(term) %>%
summarize(sentiment_score = sum(score))
# Load the AFINN lexicon
afinn <- read.csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vS4tUUP2pJ1A6crxDKSY6Be7Rp2QlZjase7ubLcPUXcnwE7xHKkXGuV3V8WpxsJFQpOEDuFpxb2qfbh/pub?gid=1069070907&single=true&output=csv")
# Load the AFINN lexicon
afinn <- read.csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vS4tUUP2pJ1A6crxDKSY6Be7Rp2QlZjase7ubLcPUXcnwE7xHKkXGuV3V8WpxsJFQpOEDuFpxb2qfbh/pub?gid=1069070907&single=true&output=csv")
# Convert the corpus to a tidy format
tidy_corpus <- tidy(corpus)
# Perform sentiment analysis
sentiment_analysis <- tidy_corpus %>%
inner_join(afinn, by = c("term" = "word")) %>%
group_by(term) %>%
summarize(sentiment_score = sum(score))
p_load(pacman,ggplot2,zoo,tm,SnowballC,textcat,caTools,rpart,rpart.plot,randomForest,caret,e1071,wordcloud,psych,tidytext, dplyr)
# Perform sentiment analysis
sentiment_analysis <- tidy_corpus %>%
inner_join(afinn, by = c("term" = "word")) %>%
group_by(term) %>%
summarize(sentiment_score = sum(score))
View(corpus)
corpus[[1]]$content
tidy_corpus[[1]]$content
View(tidy_corpus)
View(afinn)
View(tidy_corpus)
# Perform sentiment analysis
sentiment_analysis <- tidy_corpus %>%
inner_join(afinn, by = c("text" = "word")) %>%
group_by(text) %>%
summarize(sentiment_score = sum(score))
# Perform sentiment analysis
sentiment_analysis <- tidy_corpus %>%
inner_join(afinn, by = c("text" = "word")) %>%
group_by(text) %>%
summarize(sentiment_score = sum(value))
# Classify words as positive or negative based on sentiment score
positive_words <- sentiment_analysis %>% filter(sentiment_score > 0) %>% select(text)
negative_words <- sentiment_analysis %>% filter(sentiment_score < 0) %>% select(text)
# Generate word cloud for positive words
wordcloud(words = positive_words$term, freq = NULL, random.order = FALSE, colors = "green")
# Generate word cloud for positive words
wordcloud(words = positive_words$text, freq = NULL, random.order = FALSE, colors = "green")
View(positive_words)
View(sentiment_analysis)
# Perform sentiment analysis
sentiment_analysis <- tidy_corpus %>%
inner_join(afinn, by = c(term = "word")) %>%
group_by(term) %>%
summarize(sentiment_score = sum(score))
# Convert the corpus to a tidy format
tidy_corpus <- tidy(reviewsSparse)
# Convert the corpus to a tidy format
tidy_corpus <- tidy(sparse)
# Perform sentiment analysis
sentiment_analysis <- tidy_corpus %>%
inner_join(afinn, by = c(term = "word")) %>%
group_by(term) %>%
summarize(sentiment_score = sum(score))
# Perform sentiment analysis
sentiment_analysis <- tidy_corpus %>%
inner_join(afinn, by = c(term = "word")) %>%
group_by(term) %>%
summarize(sentiment_score = sum(value))
View(sentiment_analysis)
# Classify words as positive or negative based on sentiment score
positive_words <- sentiment_analysis %>% filter(sentiment_score > 0) %>% select(term)
negative_words <- sentiment_analysis %>% filter(sentiment_score < 0) %>% select(term)
# Generate word cloud for positive words
wordcloud(words = positive_words$text, freq = NULL, random.order = FALSE, colors = "green")
# Generate word cloud for positive words
wordcloud(words = positive_words$term, freq = NULL, random.order = FALSE, colors = "green")
# Generate word cloud for positive words
wordcloud(words = positive_words$term, freq = NULL, random.order = FALSE, colors = "green")
View(negative_words)
View(positive_words)
# Classify words as positive or negative based on sentiment score
positive_words <- sentiment_analysis %>% filter(sentiment_score > 0)
View(positive_words)
# Generate word cloud for positive words
wordcloud(words = positive_words$term, freq = NULL, random.order = FALSE, colors = "green")
# Generate word cloud for positive words
wordcloud(words = positive_words$term, freq = positive_words$, random.order = FALSE, colors = "green")
# Generate word cloud for positive words
wordcloud(words = positive_words$term, freq = positive_words$sentiment_score, random.order = FALSE, colors = "green")
View(sparse)
negative_words <- sentiment_analysis %>% filter(sentiment_score < 0)
# Generate word cloud for negative words
wordcloud(words = negative_words$term, freq = negative_words$sentiment_score, random.order = FALSE, colors = "red")
knitr::opts_chunk$set(echo = TRUE)
p_load(pacman,qdap,ggplot2,forcats,tidyverse,dplyr,tidyr,ggthemes, wordcloud, stringr)
knitr::opts_chunk$set(echo = TRUE)
library(pacman)
p_load(pacman,qdap,ggplot2,forcats,tidyverse,dplyr,tidyr,ggthemes, wordcloud, stringr)
hotelReview <- read.csv("tripadvisor_hotel_reviews.csv")
head(hotelReview)
pos_neg = hotelReview%>%
select(Review)%>%
unnest_tokens(output = word, input = Review)%>%
inner_join(get_sentiments('bing'))
p_load(pacman,qdap,ggplot2,forcats,tidyverse,dplyr,tidyr,ggthemes, wordcloud, stringr,tidytext)
pos_neg = hotelReview%>%
select(Review)%>%
unnest_tokens(output = word, input = Review)%>%
inner_join(get_sentiments('bing'))
head(pos_neg)
ggplot(pos_neg,aes(x=sentiment,fill=sentiment))+
geom_bar()+
guides(fill = F)+
theme_economist()
pos_neg = hotelReview%>%
select(Review)%>%
unnest_tokens(output = word, input = Review)%>%
inner_join(get_sentiments('bing'))
head(pos_neg)
ggplot(pos_neg,aes(x=sentiment,fill=sentiment))+
geom_bar()+
guides(fill = F)+
theme_economist()
options(scipen=999)
pos_neg = hotelReview%>%
select(Review)%>%
unnest_tokens(output = word, input = Review)%>%
inner_join(get_sentiments('bing'))
head(pos_neg)
ggplot(pos_neg,aes(x=sentiment,fill=sentiment))+
geom_bar()+
guides(fill = F)+
theme_economist()
options(scipen=999)
ggplot(pos_neg,aes(x=sentiment,fill=sentiment))+
geom_bar()+
guides(fill = F)
rating_sentiment =
hotelReview %>%
select(Review,Rating)%>%
unnest_tokens(output=word,input=Review)%>%
inner_join(get_sentiments('bing'))%>%
group_by(Rating,sentiment)%>%
summarize(amount = n())%>%
mutate(proportion = amount/sum(amount))
rating_sentiment %>%
ggplot(aes(x=review_rating,y=proportion,fill=sentiment))+
geom_col()
rating_sentiment %>%
ggplot(aes(x=Rating,y=proportion,fill=sentiment))+
geom_col()
wordcloudData =
hotelReview%>%
select(Review)%>%
unnest_tokens(output=word,input=Review)%>%
anti_join(stop_words)%>%
inner_join(get_sentiments('bing'))%>%
count(sentiment,word,sort=T)%>%
spread(key=sentiment,value = n,fill=0)%>%
data.frame()
rownames(wordcloudData) = wordcloudData[,'word']
wordcloudData = wordcloudData[,c('positive','negative')]
set.seed(42)
comparison.cloud(term.matrix = wordcloudData2,scale = c(2,0.5),max.words = 200, rot.per=0)
comparison.cloud(term.matrix = wordcloudData,scale = c(2,0.5),max.words = 200, rot.per=0)
corpus = VCorpus(VectorSource(data$Review))
knitr::opts_chunk$set(echo = TRUE)
library(pacman)
p_load(pacman,qdap,ggplot2,forcats,tidyverse,dplyr,tidyr,ggthemes, wordcloud, stringr,tidytext, psych)
hotelReview <- read.csv("tripadvisor_hotel_reviews.csv")
head(hotelReview)
describe(hotelReview)
#characters
hotelReview%>%
summarize(mean_character = mean(nchar(Review)), median_character = median(nchar(Review)))
#words
hotelReview%>%
summarize(mean_words = mean(str_count(string = Review,pattern = '\\S+')), median_words = median(str_count(string = Review,pattern = '\\S+')))
most_common_word = freq_terms(text.var=hotelReview$Review,top=25,stopwords =
c(Top200Words,tm::stopwords("english"),"hotel","room","stay","n't"))
ggplot(most_common_word,aes(x = fct_reorder(WORD, FREQ, .desc=FALSE),y=FREQ))+
geom_bar(stat = "identity",fill = "steelblue")+
xlab("Word")+
ylab("Frequency")+
theme_classic()+
coord_flip()
table(hotelReview$Rating)
ggplot(data=hotelReview,aes(x=Rating))+
geom_bar(fill='sienna')
data$Positive <- as.factor(data$Rating > 3)
table(hotelReview$Rating)
ggplot(data=hotelReview,aes(x=Rating))+
geom_bar(fill='sienna')
pos_neg = hotelReview%>%
select(Review)%>%
unnest_tokens(output = word, input = Review)%>%
inner_join(get_sentiments('bing'))
head(pos_neg)
ggplot(pos_neg,aes(x=sentiment,fill=sentiment))+
geom_bar()+
guides(fill = F)
options(scipen=999)
rating_sentiment =
hotelReview %>%
select(Review,Rating)%>%
unnest_tokens(output=word,input=Review)%>%
inner_join(get_sentiments('bing'))%>%
group_by(Rating,sentiment)%>%
summarize(amount = n())%>%
mutate(proportion = amount/sum(amount))
rating_sentiment %>%
ggplot(aes(x=Rating,y=proportion,fill=sentiment))+
geom_col()
wordcloudData =
hotelReview%>%
select(Review)%>%
unnest_tokens(output=word,input=Review)%>%
anti_join(stop_words)%>%
inner_join(get_sentiments('bing'))%>%
count(sentiment,word,sort=T)%>%
spread(key=sentiment,value = n,fill=0)%>%
data.frame()
rownames(wordcloudData) = wordcloudData[,'word']
wordcloudData = wordcloudData[,c('positive','negative')]
set.seed(42)
comparison.cloud(term.matrix = wordcloudData,scale = c(2,0.5),max.words = 200, rot.per=0)
p_unload(...)
p_loaded()
p_unload(all)
install.packages('tinytex')
tinytex::install_tinytex()
install.packages('tinytex')
install.packages("tinytex")
install.packages('tinytex')
unlink("Sentiment_Analysis_cache", recursive = TRUE)
tinytex::install_tinytex()
unlink("Sentiment_Analysis_cache", recursive = TRUE)
tinytex::parse_packages()
rmarkdown::find_pandoc(version = '2.9.1')
knitr::opts_chunk$set(echo = TRUE)
tinytex::install_tinytex()
